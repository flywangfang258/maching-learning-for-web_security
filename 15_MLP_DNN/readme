TensorFlow的基础知识：
操作、张量、变量、会话以及TensorFlow的运行模式，包括单机模式和集群模式。

神经网络由输入层、隐藏层和输出层组成，如果隐藏层只有一层，就是最简单的单层神经网络。
如果隐藏层具有多层，就是多层感知机，深度学习就是多层感知机的一种。
狭义的多层感知机，要求必须是全连接的，全连接是指每个隐藏层的任何一个节点，都与下一层隐藏层的全部节点连接。

深度神经网络（Deep Neural Network, DNN）就是一种全连接的多层感知机。
常见的深度学习包括DNN, 卷积神经网络（Convolutional Neural Network， CNN）、循环神经网络（Recurrent Neural Network， RNN）

TensorFlow是google研发的第二代人工智能学习系统。
Tensor：张量，即N维数组
Flow：流，即基于数据流图的计算
TensorFlow为张量从流图的一端流动到另一端的计算过程。
TensorFlow将复杂的数据结构传输至人工智能神经网络中进行分析和处理。

操作：把算法表示成一个个操作的叠加，可以非常清晰地看到数据之间的关系。在TensorFlow中，当数据流过操作节点的时候就可以对数据进行操作，
    一个操作可以有0个或多个输入，产生0个或多个输出。一个操作可能是一次数学运算，一个变量或常量，一个数据流走向控制，一次文件IO或者
    一次网络通信。其中一个常量可以看成没有输入、只有一个固定输出的操作

张量:在计算图中，每个边就代表数据从一个操作流到另一个操作。这些数据被表示为张量，一个张量可以看成一个多维的数组或高维的矩阵。
    注意：TensorFlow中的张量本身并没有保存任何值，张量仅仅提供了访问数值的一个接口，可以看成数值的一种引用。在TensorFlow的实际使用中也可以发现，
    在run之前的张量并没有分配空间，此时的张量仅仅表示了一种数值的抽象，用来连接不同的节点，表示数据在不同操作之间的流动。

变量：变量是计算图中可以改变的节点。比如当计算权重的时候，随着迭代的进行，每次权重的值会发生相应的变化，这样的值就可以当作变量。在实际处理时，
    一般把需要训练的值指定为变量。在使用变量的时候需要指定变量的初始值，变量的大小和数据类型就是根据初始值来推断的。

会话：在TensorFlow中，所有的操作都必须在会话（session）中执行，会话负责分配和管理各种资源。
     在会话中提供了一个run方法，可以用它来执行计算图整体或者其中的一部分节点。在执行run方法时，还需要用feed_dict把相关数据输入到计算图。
     当run被调用时，TensorFlow将会从指定的输出节点开始，向前查找所有的依赖节点，所依赖节点都将被执行。这些操作随后被分配到物理执行单元上（如CPU\GPU），
     这种分配规则由TensorFlow中的分配算法决定。


逻辑回归、Softmax回归及线性回归都是基于线性模型。
Logistic Regression 主要处理二分类问题
Softmax Regression 主要处理多分类问题
Softmax回归就是逻辑回归的一般形式。


get post区别
字符串 查eval
跟踪http、tcp流
指令http解码
邮件正文
邮件附件 =
base64 解码， 转bin， 微步


SpamBase入门级的垃圾邮件分类训练集，SpamBase的数据不是原始的邮件内容而是已经特征化的数据，对应的特征是统计的关键字及特殊符号的词频，
        一共58个属性，其中最后一个是垃圾邮件的标记位。数据来源为4601封邮件，其中1813封为垃圾邮件。57维特征。